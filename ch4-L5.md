# ۲۴ وب اسکرپینگ (Web Scraping)

## ۱.۲۴ مقدمه

این فصل شما را با مبانی وب اسکرپینگ با استفاده از rvest آشنا می‌کند. وب اسکرپینگ ابزار بسیار مفیدی برای استخراج داده از صفحات وب است. برخی از وب‌سایت‌ها یک API ارائه می‌دهند، مجموعه‌ای از درخواست‌های ساختاریافته HTTP که داده را به عنوان JSON برمی‌گردانند، که شما با استفاده از تکنیک‌های فصل ۲۳ آن را مدیریت می‌کنید. در جایی که ممکن است، باید از API استفاده کنید، زیرا معمولاً داده‌های قابل اعتمادتری به شما می‌دهد. با این حال، متأسفانه برنامه‌نویسی با APIهای وب خارج از محدوده این کتاب است. به جای آن، ما در حال آموزش scraping هستیم، تکنیکی که چه یک سایت API ارائه دهد یا نه، کار می‌کند.

در این فصل، ابتدا در مورد اخلاق و قوانین scraping بحث خواهیم کرد قبل از اینکه به مبانی HTML بپردازیم. سپس اصول انتخابگرهای CSS را برای یافتن عناصر خاص در صفحه یاد خواهید گرفت، و نحوه استفاده از توابع rvest برای دریافت داده از متن و ویژگی‌ها از HTML و وارد کردن آنها به R را خواهید آموخت. سپس برخی تکنیک‌ها را برای فهمیدن اینکه چه انتخابگر CSS برای صفحه‌ای که در حال scraping آن هستید نیاز دارید، بحث خواهیم کرد، قبل از اینکه با چند مطالعه موردی و یک بحث مختصر در مورد وب‌سایت‌های پویا به پایان برسیم.

### ۱.۱.۲۴ پیش‌نیازها

در این فصل، بر روی ابزارهای ارائه شده توسط rvest تمرکز خواهیم کرد. rvest عضوی از tidyverse است، اما عضو اصلی نیست بنابراین باید آن را به صورت صریح بارگذاری کنید. همچنین کل tidyverse را بارگذاری خواهیم کرد زیرا به طور کلی برای کار با داده‌هایی که scrape کرده‌ایم مفید است.

```{r}
library(tidyverse)
library(rvest)
```

## ۲.۲۴ اخلاق و قوانین scraping

قبل از اینکه شروع به بحث در مورد کدی که برای انجام وب اسکرپینگ نیاز دارید کنیم، باید در مورد اینکه آیا این کار قانونی و اخلاقی است یا نه صحبت کنیم. به طور کلی، وضعیت در مورد هر دوی این موارد پیچیده است.

قوانین بسیار به جایی که زندگی می‌کنید بستگی دارد. با این حال، به عنوان یک اصل کلی، اگر داده‌ها عمومی، غیرشخصی و واقعی باشند، احتمالاً مشکلی ندارید. این سه عامل مهم هستند زیرا آنها به شرایط و ضوابط سایت، اطلاعات قابل شناسایی شخصی و حق نسخه‌برداری مربوط می‌شوند:

- **عمومی (Public)**: اگر داده‌ها عمومی نیستند، احتمالاً قانونی نیست که آنها را scrape کنید. مثلاً معمولاً OK است که دیدگاه‌های یک فیلم را از یک سایت عمومی scrape کنید، اما scraping کردن دوستان شما (یا اطلاعات دیگری که فقط با لاگین کردن قابل مشاهده است) از Facebook قانونی نیست. به عنوان یک قانون کلی، اگر نیاز به لاگین شدن دارید، احتمالاً نمی‌توانید scrape کنید.

- **غیرشخصی (Non-personal)**: حتی اگر داده‌ها عمومی باشند، ممکن است داده‌های شخصی باشند (مانند آدرس ایمیل یا شماره تلفن). این داده‌ها ممکن است در اروپا تحت مقررات GDPR باشند و استفاده از آنها ممکن است تابع سایر قوانین باشد.

- **واقعی (Factual)**: واقعیات نمی‌توانند copyright داشته باشند، بنابراین scraping کردن یک لیست از نام‌ها، مشخصات یا آمارها معمولاً OK است. اما داده‌های ادبی (مانند متن، تصاویر و غیره) محافظت شده هستند، بنابراین نمی‌توانید مثلاً متن کامل یک کتاب یا شعر را scrape کنید.

همیشه باید شرایط و ضوابط سایت (Terms and Conditions) را بخوانید تا ببینید آیا scraping مجاز است یا نه. همیشه شرایط و ضوابط را بخوانید حتی اگر شما یک وکیل نیستید: این ممکن است از شما در دادگاه نجات ندهد، اما به شما یک ایده خوب از اینکه آیا در حال انجام کاری هستید که سازمان دوست دارد یا نه می‌دهد.

همچنین باید دانشجویان اصول اخلاقی تحقیق باشید. اینطور نیست که چون چیزی قانونی است، بدان معنا باشد که اخلاقی است. در حالی که اخلاق به طور ذاتی امری فازی و وابسته به زمینه است، یک چارچوب خوب برای تصمیم‌گیری در مورد اینکه آیا کار شما اخلاقی است یا نه، این است که به رضایت آگاهانه (informed consent) فکر کنید. قبلاً در مورد استفاده از شبیه‌سازی برای کشف اطلاعات در مورد رفتار افراد صحبت کرده‌ایم. اما بیایید اینجا یک نمونه بد از استفاده از scraping داده‌های عمومی را مطرح کنیم، یک مطالعه که داده‌های پروفایل کاربران OkCupid را scrape کرد و بدون رضایت آنها منتشر کرد.

علاوه بر رضایت آگاهانه، همچنین باید در مورد اینکه آیا داده‌های شما ممکن است برای آسیب‌رساندن به افرادی استفاده شود فکر کنید. برای مثال، با ساخت یک وب‌سایت عمومی که به افراد اجازه می‌دهد قضاوت‌های کیفری را جستجو کنند که با نام مرتبط شده‌اند، ممکن است به بازیابی پس از محکومیت یا شروع مجدد زندگی آنها آسیب برسانید. در این مثال خاص، وب‌سایت که پیش از این مشکوک به بودن قانونی بود، این عدم رضایت با جانشینی نام‌ها با شماره‌های پرونده تعمیق یافته است.

خلاصه اینکه، باید از ایجاد فروشگاه‌های داده جدید که نقاط ضعف کسانی را که نمی‌توانند خودشان را از مخاطرات محافظت کنند افزایش دهد، خودداری کنید.

اگر می‌خواهید اطلاعات بیشتری کسب کنید، توصیه می‌کنیم از اطلاعات زیر شروع کنید:

- مقاله `r4ds_scrape("https://blog.rstudio.com/2022/01/06/web-scraping-legal-ethical-considerations/")` اطلاعات بیشتری در مورد ملاحظات قانونی و اخلاقی scraping می‌دهد.
- این درس از چارلستون دیجیتال هیومانیتیز، `r4ds_scrape("https://digitalhumanities.berkeley.edu/blog/scraping-data-web-basics-ethics/")` اطلاعات خوبی در مورد ملاحظات اخلاقی می‌دهد.
- `r4ds_scrape("https://www.eff.org/issues/coders/reverse-engineering-faq")` صفحه مفید برای فهم بهتر قوانین حق نسخه‌برداری در ایالات متحده است.

## ۳.۲۴ مبانی HTML

برای scrape کردن صفحات وب، باید ابتدا کمی در مورد **HTML** بدانید، زبانی که صفحات وب با آن توصیف می‌شوند. HTML مخفف **H**yper**T**ext **M**arkup **L**anguage است و به این شکل است:

```html
<html>
<head>
  <title>Page title</title>
</head>
<body>
  <h1 id='first'>A heading</h1>
  <p>Some text &amp; <b>some bold text.</b></p>
  <img src='myimg.png' width='100' height='100'>
</body>
```

HTML دارای یک ساختار درختی است که با **تگ‌ها** (tags) مانند `<tag></tag>` شکل می‌گیرد. همانطور که می‌بینید، تگ‌های HTML مشابه به توابع R هستند: تگ‌ها (مانند نام تابع) تعریف می‌کند که چه نوع **element**ی است، و **attributes** (مانند آرگومان‌های تابع) اطلاعات اضافی را فراهم می‌کنند. و مانند توابع R که می‌توانند تو در تو باشند، HTML tags همچنین می‌توانند تو در تو باشند.

اکثر تگ‌ها به صورت جفتی هستند: یک تگ شروع (مانند `<tag>`) و یک تگ پایان (مانند `</tag>`). محتوای بین تگ شروع و پایان، محتوای element است. برخی تگ‌ها محتوا ندارند و بنابراین نیازی به تگ پایان ندارند، مانند تگ `<img>` در بالا.

به نظر ما کمی از HTML را یاد گرفتن ایده خوبی است زیرا به شما کمک می‌کند درک کنید که چگونه صفحات وب ساخته می‌شوند و چگونه می‌توانید داده‌ها را از آنها استخراج کنید. اگر می‌خواهید بیشتر بیاموزید، توصیه می‌کنیم MDN Web Docs را بررسی کنید، یک منبع بسیار خوب برای یادگیری HTML و CSS.

### ۱.۳.۲۴ عناصر (Elements)

همه تگ‌ها حاوی یک عنصر HTML هستند، که بخش ساختاری از HTML هستند. برخی از تگ‌های رایج شامل موارد زیر هستند:

- هر صفحه HTML باید در یک تگ `<html>` باشد و داخل آن باید دو فرزند داشته باشد: `<head>` (حاوی ابرداده صفحه مانند عنوان) و `<body>` (حاوی محتوای واقعی صفحه).

- تگ‌های بلوکی که ساختار سلسله مراتبی صفحه را تعیین می‌کنند مانند سرفصل‌ها (`<h1>`, `<h2>`, `<h3>`, و غیره) و پاراگراف‌ها (`<p>`).

- تگ‌های inline که محتوای متن را فرمت می‌دهند، مانند `<b>` (bold)، `<i>` (italic) و `<a>` (link).

اگر با HTML آشنایی ندارید و می‌خواهید یاد بگیرید بیشتر، توصیه می‌کنیم `r4ds_scrape("https://developer.mozilla.org/en-US/docs/Web/HTML")` را بررسی کنید.

### ۲.۳.۲۴ محتوا

اکثر عناصر محتوا دارند، متنی که بین تگ‌های شروع و پایان قرار گرفته است. rvest به شما این امکان را می‌دهد که با `html_text2()` محتوا را استخراج کنید:

```{r}
html <- minimal_html("
  <p>This is a paragraph</p>
  <ul>
    <li>This is a bulleted list</li>
  </ul>
")

html |> 
  html_elements("p") |> 
  html_text2()
#> [1] "This is a paragraph"

html |> 
  html_elements("li") |> 
  html_text2()
#> [1] "This is a bulleted list"
```

توجه داشته باشید که محتوا فقط ممکن است شامل متن باشد یا ممکن است حاوی تگ‌های تو در تو دیگری باشد. به طور مثال در مثال بالا، `<p>` یک تگ متن ساده دارد، اما در این مثال، `<p>` یک تگ inline `<b>` دارد:

```{r}
html <- minimal_html("
  <p>This is a paragraph with <b>bold</b> text</p>
")

html |> 
  html_element("p") |> 
  html_text2()
#> [1] "This is a paragraph with bold text"
```

### ۳.۳.۲۴ ویژگی‌ها (Attributes)

تگ‌ها می‌توانند **attributes** داشته باشند که شبیه به نام آرگومان‌های یک تابع هستند. attributes به صورت `name=value` در داخل تگ شروع نوشته می‌شوند. دو مورد از رایج‌ترین attributes عبارتند از id و class که با CSS selectors استفاده می‌شوند، که در بخش بعدی بیشتر در مورد آن صحبت خواهیم کرد.

- `id` یک شناسه منحصر به فرد برای یک element در صفحه است.
- `class` یک شناسه است که می‌تواند توسط چندین element در صفحه به اشتراک گذاشته شود.

می‌توانید از `html_attr()` برای استخراج یک attribute واحد استفاده کنید:

```{r}
html <- minimal_html("
  <p><a href='https://en.wikipedia.org/wiki/Cat'>cats</a></p>
  <p><a href='https://en.wikipedia.org/wiki/Dog'>dogs</a></p>
")

html |> 
  html_elements("a") |> 
  html_attr("href")
#> [1] "https://en.wikipedia.org/wiki/Cat"
#> [2] "https://en.wikipedia.org/wiki/Dog"
```

یا `html_attrs()` برای دریافت تمام attributes:

```{r}
html <- minimal_html("
  <p id='first'>This is a paragraph</p>
  <p class='important'>This is an important paragraph</p>
")

html |> 
  html_elements("p") |> 
  html_attrs()
#> [[1]]
#> id 
#> "first" 
#> 
#> [[2]]
#> class 
#> "important"
```

## ۴.۲۴ استخراج داده با CSS selectors

CSS مخفف cascading style sheets است و یک ابزار برای تعریف قالب‌بندی بصری اسناد HTML است. CSS شامل یک زبان کوچک و جذاب برای مشخص کردن عناصر در یک صفحه HTML است که **CSS selectors** نامیده می‌شود. CSS selectors تعریف الگوهایی برای یافتن عناصر HTML را تعریف می‌کنند و در وب اسکرپینگ بسیار مفید هستند زیرا کاری که rvest با آنها انجام می‌دهد این است که برای یافتن عناصری که می‌خواهید استخراج کنید استفاده می‌شوند.

ما در مورد سه نوع selector صحبت خواهیم کرد:

- selector برای عناصر با نام tag خاص
- selector برای عناصر با id یا class خاص
- selector برای عناصر با attribute خاص

سپس در مورد نحوه ترکیب selectors صحبت خواهیم کرد.

### ۱.۴.۲۴ Selectors پایه

ساده‌ترین CSS selectors فقط یک نام tag را انتخاب می‌کنند:

- `p` تمام عناصر `<p>` را انتخاب می‌کند.
- `b` تمام عناصر `<b>` را انتخاب می‌کند.
- `a` تمام عناصر `<a>` را انتخاب می‌کند.

همچنین می‌توانید عناصر را با استفاده از `id` یا `class` انتخاب کنید. `#` یک id را انتخاب می‌کند و `.` یک class را انتخاب می‌کند:

- `#first` عنصر با `id = "first"` را انتخاب می‌کند.
- `.important` تمام عناصر با `class = "important"` را انتخاب می‌کند.

می‌توانید نام tag و id یا class را ترکیب کنید:

- `p#first` عنصر `<p>` با `id = "first"` را انتخاب می‌کند.
- `p.important` تمام عناصر `<p>` با `class = "important"` را انتخاب می‌کند.

و می‌توانید چندین class را با ترکیب کردن چندین `.` انتخاب کنید:

- `.important.warning` تمام عناصر با `class = "important"` و `class = "warning"` را انتخاب می‌کند.

بالاخره، می‌توانید `[attr]` یا `[attr=value]` را برای انتخاب عناصر با یک attribute خاص استفاده کنید:

- `[href]` تمام عناصری که attribute `href` دارند را انتخاب می‌کند.
- `[href='https://example.com']` تمام عناصری که attribute `href` برابر با `"https://example.com"` دارند را انتخاب می‌کند.

اگر می‌خواهید بیشتر بیاموزید، یک منبع خوب این است: `r4ds_scrape("https://flukeout.github.io/")` — یک بازی مبتنی بر وب که به شما کمک می‌کند selectors پیچیده‌تر را یاد بگیرید.

### ۲.۴.۲۴ ترکیب Selectors

می‌توانید selectors را با استفاده از فضا برای ترکیب کنید تا عناصر تو در تو را انتخاب کنید:

- `p b` تمام عناصر `<b>` در داخل `<p>` را انتخاب می‌کند.
- `p.important b` تمام عناصر `<b>` در داخل `<p class="important">` را انتخاب می‌کند.

در صورت لزوم، می‌توانید از `>` برای محدود کردن به فرزندان مستقیم استفاده کنید:

- `p > b` تمام عناصر `<b>` که فرزندان مستقیم `<p>` هستند را انتخاب می‌کند.

و در نهایت می‌توانید از `,` برای ترکیب چند selector استفاده کنید:

- `p, b` تمام عناصر `<p>` و تمام عناصر `<b>` را انتخاب می‌کند.

### ۳.۴.۲۴ پیدا کردن selector مناسب

با استفاده از چیزی که در مورد selectors یاد گرفته‌اید و تا حدودی امتحان و خطا، باید بتوانید selector مناسب را برای داده‌هایی که می‌خواهید استخراج کنید پیدا کنید. یک راه خوب برای شروع، از مرورگر خود برای کمک استفاده کنید. اکثر مرورگرها ابزارهایی برای توسعه‌دهندگان دارند که به شما امکان می‌دهد HTML صفحه را ببینید و عناصر را به طور تعاملی تست کنید.

در Chrome می‌توانید با کلیک راست روی صفحه و انتخاب "Inspect" به این ابزارها دسترسی پیدا کنید. در Firefox می‌توانید با کلیک راست روی صفحه و انتخاب "Inspect Element" به این ابزارها دسترسی پیدا کنید. سپس می‌توانید روی element در صفحه کلیک کنید تا ببینید کدام قسمت از HTML آن را تعریف می‌کند.

ابزار دیگری که می‌تواند مفید باشد SelectorGadget است: `r4ds_scrape("https://rvest.tidyverse.org/articles/selectorgadget.html")`. این یک ابزار JavaScript است که به شما امکان می‌دهد به طور تعاملی selector مناسب را پیدا کنید. روی یک element کلیک کنید که می‌خواهید انتخاب کنید و SelectorGadget selector را پیشنهاد می‌دهد. سپس می‌توانید روی عناصری که نمی‌خواهید کلیک کنید تا selector را اصلاح کنید.

## ۵.۲۴ Turning a table into a data frame

یکی از متداول‌ترین ساختارهایی که با آن روبرو می‌شوید جداول HTML هستند. rvest شامل یک تابع کمکی به نام `html_table()` است که یک HTML table را تبدیل به یک data frame می‌کند:

```{r}
html <- minimal_html("
  <table>
    <tr>
      <th>Month</th>
      <th>Sales</th>
    </tr>
    <tr>
      <td>January</td>
      <td>100</td>
    </tr>
    <tr>
      <td>February</td>
      <td>200</td>
    </tr>
  </table>
")

html |> 
  html_element("table") |> 
  html_table()
#> # A tibble: 2 × 2
#>   Month    Sales
#>   <chr>    <int>
#> 1 January    100
#> 2 February   200
```

## ۶.۲۴ مطالعات موردی

برای تمرین آنچه یاد گرفته‌اید، به دو مطالعه موردی نگاه خواهیم کرد: یکی ساده‌تر و یکی پیچیده‌تر.

### ۱.۶.۲۴ Star Wars

اولین مثال ما scraping کردن اطلاعات در مورد فیلم‌های Star Wars از یک صفحه در وب‌سایت بسته rvest است. اینجا یک نمونه نسبتاً ساده است که برای درک اساسی scraping کار می‌کند.

در اینجا HTML را می‌خوانیم و یک بررسی سریع از ساختار انجام می‌دهیم:

```{r}
url <- "https://rvest.tidyverse.org/articles/starwars.html"
html <- read_html(url)
html
```

سپس از CSS selector برای یافتن تمام `<section>` های که حاوی اطلاعات فیلم‌ها هستند استفاده می‌کنیم:

```{r}
section <- html |> html_elements("section")
section
#> {xml_nodeset (7)}
#> [1] <section><h2 data-id="1">\nThe Phantom Menace\n</h2>\n<p>\nRelea ...
#> [2] <section><h2 data-id="2">\nAttack of the Clones\n</h2>\n<p>\nRe ...
#> [3] <section><h2 data-id="3">\nRevenge of the Sith\n</h2>\n<p>\nRel ...
#> [4] <section><h2 data-id="4">\nA New Hope\n</h2>\n<p>\nReleased: 19 ...
#> [5] <section><h2 data-id="5">\nThe Empire Strikes Back\n</h2>\n<p>\ ...
#> [6] <section><h2 data-id="6">\nReturn of the Jedi\n</h2>\n<p>\nRele ...
#> [7] <section><h2 data-id="7">\nThe Force Awakens\n</h2>\n<p>\nRelea ...
```

حالا می‌توانیم عنوان هر فیلم را استخراج کنیم:

```{r}
section |> 
  html_element("h2") |> 
  html_text2()
#> [1] "The Phantom Menace"      "Attack of the Clones"   
#> [3] "Revenge of the Sith"     "A New Hope"             
#> [5] "The Empire Strikes Back" "Return of the Jedi"     
#> [7] "The Force Awakens"
```

و سال انتشار هر فیلم را از پاراگراف:

```{r}
section |> 
  html_element("p") |> 
  html_text2() |> 
  str_remove("Released: ")
#> [1] "1999" "2002" "2005" "1977" "1980" "1983" "2015"
```

### ۲.۶.۲۴ IMDB top 250

در مثال دوم، ما قرار است 250 فیلم برتر IMDB را از `r4ds_scrape("https://www.imdb.com/chart/top")` استخراج کنیم. این یک مورد استفاده رایج‌تر است و شامل استخراج داده از یک جدول HTML است.

ابتدا HTML را می‌خوانیم:

```{r}
url <- "https://web.archive.org/web/20220201012049/https://www.imdb.com/chart/top/"
html <- read_html(url)
```

توجه داشته باشید که ما در اینجا از یک نسخه آرشیو شده از صفحه استفاده می‌کنیم زیرا صفحه اصلی ممکن است تغییر کند. با استفاده از ابزارهای مرورگر، می‌توانیم ببینیم که جدول در داخل یک `<table>` با `class="chart"` قرار دارد، پس می‌توانیم با این CSS selector آن را استخراج کنیم:

```{r}
table <- html |> 
  html_element(".chart") |> 
  html_table()
table
#> # A tibble: 250 × 5
#>    `Rank & Title`                            `IMDb Rating` `Your Rating`
#>    <chr>                                               <dbl> <chr>        
#>  1 "\n      1.\n      The Shawshank Redempt…              9.2 "12345678910…
#>  2 "\n      2.\n      The Godfather\n      …              9.1 "12345678910…
#>  3 "\n      3.\n      The Godfather: Part I…              9   "12345678910…
#>  4 "\n      4.\n      The Dark Knight\n    …              9   "12345678910…
#>  5 "\n      5.\n      12 Angry Men\n        …              8.9 "12345678910…
#>  6 "\n      6.\n      Schindler's List\n    …              8.9 "12345678910…
#>  # ℹ 244 more rows
```

این شامل چند ستون خالی است، اما به طور کلی کار خوبی در capture کردن اطلاعات از جدول انجام می‌دهد. با این حال، نیاز به پردازش بیشتر داریم تا استفاده از آن آسان‌تر شود. ابتدا، ستون‌ها را تغییر نام می‌دهیم تا کار با آنها آسان‌تر شود، و فضای اضافی در rank و title را حذف می‌کنیم. این کار را با `select()` (به جای `rename()`) انجام می‌دهیم تا تغییر نام و انتخاب فقط این دو ستون را در یک مرحله انجام دهیم. سپس خطوط جدید و فضاهای اضافی را حذف می‌کنیم، و سپس `separate_wider_regex()` را اعمال می‌کنیم تا title، year و rank را به متغیرهای جداگانه استخراج کنیم.

```{r}
ratings <- table |>
  select(
    rank_title_year = `Rank & Title`,
    rating = `IMDb Rating`
  ) |> 
  mutate(
    rank_title_year = str_replace_all(rank_title_year, "\n +", " ")
  ) |> 
  separate_wider_regex(
    rank_title_year,
    patterns = c(
      rank = "\\d+", "\\. ",
      title = ".+", " +\\(",
      year = "\\d+", "\\)"
    )
  )
ratings
#> # A tibble: 250 × 4
#>   rank  title                      year  rating
#>   <chr> <chr>                      <chr>  <dbl>
#> 1 1     The Shawshank Redemption   1994     9.2
#> 2 2     The Godfather              1972     9.1
#> 3 3     The Godfather: Part II     1974     9  
#> 4 4     The Dark Knight            2008     9  
#> 5 5     12 Angry Men               1957     8.9
#> 6 6     Schindler's List           1993     8.9
#> # ℹ 244 more rows
```

حتی در این مورد که بیشتر داده‌ها از سلول‌های جدول می‌آید، همچنان ارزش دارد که به HTML خام نگاهی بیندازید. اگر این کار را انجام دهید، متوجه خواهید شد که می‌توانیم با استفاده از یکی از attributes، داده اضافی اضافه کنیم. این یکی از دلایلی است که ارزش دارد کمی وقت برای کندن منبع صفحه بگذارید؛ ممکن است داده اضافی پیدا کنید، یا ممکن است مسیری کمی آسان‌تر برای تجزیه پیدا کنید.

```{r}
html |> 
  html_elements("td strong") |> 
  head() |> 
  html_attr("title")
#> [1] "9.2 based on 2,536,415 user ratings"
#> [2] "9.1 based on 1,745,675 user ratings"
#> [3] "9.0 based on 1,211,032 user ratings"
#> [4] "9.0 based on 2,486,931 user ratings"
#> [5] "8.9 based on 749,563 user ratings" 
#> [6] "8.9 based on 1,295,705 user ratings"
```

می‌توانیم این را با داده‌های جدولی ترکیب کنیم و دوباره `separate_wider_regex()` را برای استخراج قسمتی از داده که به آن اهمیت می‌دهیم اعمال کنیم:

```{r}
ratings |>
  mutate(
    rating_n = html |> html_elements("td strong") |> html_attr("title")
  ) |> 
  separate_wider_regex(
    rating_n,
    patterns = c(
      "[0-9.]+ based on ",
      number = "[0-9,]+",
      " user ratings"
    )
  ) |> 
  mutate(
    number = parse_number(number)
  )
#> # A tibble: 250 × 5
#>   rank  title                    year  rating  number
#>   <chr> <chr>                    <chr>  <dbl>   <dbl>
#> 1 1     The Shawshank Redemption 1994     9.2 2536415
#> 2 2     The Godfather            1972     9.1 1745675
#> 3 3     The Godfather: Part II   1974     9   1211032
#> 4 4     The Dark Knight          2008     9   2486931
#> 5 5     12 Angry Men             1957     8.9  749563
#> 6 6     Schindler's List         1993     8.9 1295705
#> # ℹ 244 more rows
```

## ۷.۲۴ وب‌سایت‌های پویا

تا کنون بر روی وب‌سایت‌هایی تمرکز کرده‌ایم که در آنها `html_elements()` همان چیزی را که در مرورگر می‌بینید برمی‌گرداند و در مورد نحوه تجزیه آنچه برمی‌گرداند و نحوه سازماندهی آن اطلاعات در data frameهای tidy بحث کرده‌ایم. از زمان به زمان، با این حال، با سایتی روبرو خواهید شد که در آن `html_elements()` و دوستانش چیزی شبیه به آنچه در مرورگر می‌بینید برنمی‌گرداند. در بسیاری از موارد، این به این دلیل است که شما در حال تلاش برای scrape کردن یک وب‌سایت هستید که محتوای صفحه را به صورت پویا با javascript تولید می‌کند. این در حال حاضر با rvest کار نمی‌کند، زیرا rvest HTML خام را دانلود می‌کند و هیچ javascript اجرا نمی‌کند.

هنوز امکان scrape کردن این نوع سایت‌ها وجود دارد، اما rvest نیاز دارد از یک فرآیند گران‌تر استفاده کند: شبیه‌سازی کامل مرورگر وب از جمله اجرای تمام javascript. این قابلیت در زمان نگارش موجود نیست، اما چیزی است که ما به طور فعال روی آن کار می‌کنیم و ممکن است تا زمانی که شما این را بخوانید در دسترس باشد. از بسته chromote استفاده می‌کند که در واقع مرورگر Chrome را در پس‌زمینه اجرا می‌کند و ابزارهای اضافی به شما می‌دهد تا با سایت تعامل داشته باشید، مانند تایپ کردن متن و کلیک کردن دکمه‌ها. برای جزئیات بیشتر به وب‌سایت rvest مراجعه کنید.

## ۸.۲۴ خلاصه

در این فصل، در مورد چرایی، چرا نه و چگونگی استخراج داده از صفحات وب یاد گرفتید. ابتدا در مورد مبانی HTML و استفاده از انتخابگرهای CSS برای اشاره به عناصر خاص یاد گرفتید، سپس در مورد استفاده از بسته rvest برای دریافت داده از HTML به R یاد گرفتید. سپس وب اسکرپینگ را با دو مطالعه موردی نشان دادیم: یک سناریوی ساده‌تر برای استخراج داده در مورد فیلم‌های StarWars از وب‌سایت بسته rvest و یک سناریوی پیچیده‌تر برای استخراج 250 فیلم برتر از IMDB.

جزئیات فنی استخراج داده از وب می‌تواند پیچیده باشد، به ویژه هنگام برخورد با سایت‌ها، با این حال ملاحظات قانونی و اخلاقی می‌توانند حتی پیچیده‌تر باشند. مهم است که قبل از شروع به استخراج داده، خود را در مورد هر دوی این موارد آموزش دهید.

این ما را به پایان بخش import کتاب می‌رساند که در آن تکنیک‌هایی برای دریافت داده از جایی که زندگی می‌کند (صفحات گسترده، پایگاه‌های داده، فایل‌های JSON و وب‌سایت‌ها) به فرم tidy در R یاد گرفته‌اید. حالا وقت آن است که نگاه خود را به یک موضوع جدید معطوف کنیم: بهره‌برداری حداکثر از R به عنوان یک زبان برنامه‌نویسی.
